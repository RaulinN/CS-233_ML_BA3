{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Session 3: K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will work with your first machine learning algorithm: K-means clustering. You will be asked to cluster the mnist dataset using the k-means algorithm. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from base64 import b64decode\n",
    "from json import loads\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# set matplotlib to display all plots inline with the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help functions we use to load the data and visualize the images\n",
    "\n",
    "Just run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    \"\"\"\n",
    "    parse the digits file into tuples of \n",
    "    (digit label, numpy array of vector representation of digit image)\n",
    "    \"\"\"\n",
    "    digit = loads(x)\n",
    "    array = np.frombuffer(b64decode(digit[\"data\"]),dtype=np.ubyte)\n",
    "    array = array.astype(np.float64)\n",
    "    return (digit[\"label\"], array)\n",
    "\n",
    "def display_digit(digit, training_or_inferred = \"training\"):\n",
    "    \"\"\" \n",
    "    graphically display a 784x1 vector, representing a digit, and show the corresponding label\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    image = digit[1]\n",
    "    plt.figure()\n",
    "    fig = plt.imshow(image.reshape(28,28))\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    if training_or_inferred == \"training\":\n",
    "        title_str = \"GT label: \"\n",
    "    else:\n",
    "        title_str = \"Inferred label: \"\n",
    "    plt.title(title_str  + str(digit[0]))\n",
    "    \n",
    "def display_vector(vector):\n",
    "    \"\"\" \n",
    "    graphically display a 784x1 vector, representing a digit, without showing the label\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    plt.figure()\n",
    "    fig = plt.imshow(vector.reshape(28,28))\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Dataset\n",
    "### Load and Visualize dataset\n",
    "\n",
    "First of all, **unzip the file 'mnist.json.zip'** and you will get the data file 'mnist.json', which contains gray-scale images of handwritten digits, from 0 to 9. \n",
    "\n",
    "Each image is of size 784 with integers in the range $[0, 255]$, and the images can be reshaped to $28 \\times 28$. The value of the pixels indicate the brightness of a pixel, that is, the higher number the brighter the pixel.\n",
    "\n",
    "Now we will load datapoints from the .json file, and split them into training and validation  datasets. We choose the first 1000 datapoints as training dataset, then 400 datapoints for validation.\n",
    "\n",
    "#### Question: What will happen if we enlarge the training dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "## load .json file\n",
    "with open(\"mnist.json\",\"r\") as f:\n",
    "    digits = list(map(parse, f.readlines()))\n",
    "    \n",
    "## split into train (1000 datapoints), validation(400 datapoints) and test(600 datapoints) datasets\n",
    "train_data = digits[:1000]\n",
    "## >>> YOUR CODE HERE: define val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure\n",
    "\n",
    "Let's study the structure of our newly-split datasets. \n",
    "\n",
    "* Each dataset is a list, in which each element is a tuple. \n",
    "* Each tuple contains the image's label and the image's pixel values. It is a pair of (label,vector), where \"label\" is a single digit and \"vector\" is an integer vector of shape (784,).\n",
    "\n",
    "Below, we study the training dataset and what the elements look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The type of training dataset is: ',type(train_data))\n",
    "print ('The number of training samples is: ',len(train_data))\n",
    "print ('The type of each data sample is: ',type(train_data[0]))\n",
    "print ('The label of the first sample image is: ',train_data[0][0])\n",
    "print ('The shape of the first sample image is: ',train_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Visualization\n",
    "\n",
    "We can use the help function 'display_digit' to display the image of each data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first training sample\n",
    "# for each digit, the first element is the label, the second one is the pixel value of the image\n",
    "display_digit(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 K-means Clustering\n",
    "\n",
    "Now we group the datapoints into k clusters with the GREAT k-means clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define some basic functions which will be used later. \n",
    "\n",
    "You will now fill in the function to initialize K cluster centers randomly. Pick K values randomly from the given dataset as initial cluster centers and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize k cluster centers randomly\n",
    "def init_centers(labelled_data, K):\n",
    "    \"\"\"\n",
    "    Randomly pick K values from the data as starting values for centers.\n",
    "    Ignore their labels.\n",
    "    \n",
    "    input: training/validation/test dataset, K (number of clusters)\n",
    "    output: a list containing initial centers, which are K different images without their labels.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    center_list = []\n",
    "    ## >>> YOUR CODE HERE\n",
    "    \n",
    "    return center_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to first initialize 10 cluster centers and then visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for init_centers, define the number of clusters (for example, 10)\n",
    "# and dispaly the initial centers\n",
    "original_centers = init_centers(train_data,10)\n",
    "for center in original_centers:\n",
    "    display_vector(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement the function for forming clusters, `build_clusters`. This function assigns every datapoint in the dataset to a cluster, based on its distance to the cluster centers. The datapoint is assigned to the nearest cluster center.\n",
    "\n",
    "Fill in the blank parts of the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign each datapoint in the input dataset to the nearest center based on current centers.\n",
    "def build_clusters(labelled_data, unlabelled_centers):\n",
    "    \"\"\"\n",
    "    given datapoints and current centers, assign each datapoint\n",
    "    to its nearest center. This builds clusters.\n",
    "    \n",
    "    Note that we do not need the label information when assign the digit, therefore, it is unsupervised\n",
    "    \n",
    "    input: labelled_data: the list of data tuples, each tuple contains (label,vector)\n",
    "           unlabelled_centers: current centers before this step\n",
    "    output: list of digits(tuples) that assigned to different centers \n",
    "    \"\"\"\n",
    "    # enumerate because centers are arrays which are unhashable\n",
    "    # (basically we assign each center a number (i.e. cluster center #x)\n",
    "    # but this is not related to the digit the cluster is supposed to represent)\n",
    "    centers_indices = range(len(unlabelled_centers))\n",
    "    \n",
    "    # initialize an empty dict for each center. The dict will contain\n",
    "    # all the datapoints that are closer to that center than to any other.\n",
    "    # That list is the cluster of that center.\n",
    "    clusters = {c: [] for c in centers_indices}\n",
    "    \n",
    "    for (label,vector) in labelled_data:\n",
    "        # for each datapoint, pick the closest center.\n",
    "        smallest_distance = float(\"inf\")\n",
    "        for cj_index in centers_indices:\n",
    "            cj = unlabelled_centers[cj_index]\n",
    "            ## >>> YOUR CODE HERE: compute L2 distance\n",
    "\n",
    "            \n",
    "            if distance < smallest_distance:\n",
    "                closest_center_index = cj_index\n",
    "                smallest_distance = distance\n",
    "        # allocate that datapoint to the cluster of that center.\n",
    "        clusters[closest_center_index].append((label,vector))\n",
    "    return list(clusters.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the results after building clusters based on train dataset and initial centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for building clusters\n",
    "clusters = build_clusters(train_data, original_centers)\n",
    "# the number of clusters should be the same as the number of centers, which is 10 here\n",
    "print ('the number of clusters are: ',len(clusters))\n",
    "for i,cluster in enumerate(clusters):\n",
    "    print ('the number of data tuples assigned to the %d cluster is %d'%(i+1,len(cluster)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we take a look at what the clusters look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for building clusters\n",
    "# display digits that assigned to the same cluster, \n",
    "# here, take the first 3 datapoints from the first cluster as example.\n",
    "for data_tuple in clusters[0][:3]:\n",
    "    display_digit(data_tuple, \"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fill in the function `mean_cluster()`, which finds the cluster center of a given cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the center of a cluster\n",
    "def mean_cluster(labelled_cluster):\n",
    "    \"\"\"\n",
    "    compute the mean (i.e. the center at the middle) of a list of vectors (a cluster).\n",
    "    take the sum and then divide by the size of the cluster.\n",
    "    assume all datapoints in labelled_cluster are labelled.\n",
    "    \n",
    "    input: labelled_center: one cluster \n",
    "    output: the mean of this cluster through all datapoints in this cluster\n",
    "    \"\"\"  \n",
    "    # element-wise sums a list of arrays. The initial value is the first date vector\n",
    "    sum_of_points = labelled_cluster[0][1].copy()\n",
    "    \n",
    "    ## >>> YOUR CODE HERE: compute sum of all datapoints in a cluster\n",
    "    \n",
    "    \n",
    "    # mean w.r.t the size of the cluster\n",
    "    ## >>> YOUR CODE HERE: compute the mean from the sum\n",
    "\n",
    "    \n",
    "    return mean_of_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill in the function `move_centers()`, which uses `mean_cluster()` to compute the cluster centers of all the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update centers\n",
    "def move_centers(labelled_clusters):\n",
    "    \"\"\"\n",
    "    return a list of centers corresponding to the current clusters by computing their means.\n",
    "    \n",
    "    input: labelled_centers: a list of current clusters \n",
    "    output: new_centers: a list of new centers \n",
    "    \"\"\"\n",
    "    new_centers = []\n",
    "    # compute the mean of each cluster\n",
    "    for cluster in labelled_clusters:\n",
    "        new_centers.append(mean_cluster(cluster))\n",
    "    return new_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the new centers look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for the first movement of centers\n",
    "new_centers = move_centers(clusters)\n",
    "# display new centers\n",
    "for center in new_centers:\n",
    "    display_vector(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is an iteration of first finding cluster centers, then building new clusters. We iterate between these two steps until we converge. Fill in the function below to perform this iteration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_until_convergence(labelled_data, unlabelled_centers, labelled_clusters):\n",
    "    \"\"\"\n",
    "    build clusters around centers, then keep moving the centers\n",
    "    until the moves are no longer significant, i.e. we've found\n",
    "    the best-fitting centers for the data.\n",
    "    \n",
    "    input: labelled_data: training datasets \n",
    "           unlabelled_centers: initial centers\n",
    "           labelled_clusters: initial clusters based on inital centers\n",
    "    output: \n",
    "           labelled_clusters: clusters from the last update\n",
    "           unlabelled_centers: centers from the last update\n",
    "    \"\"\"\n",
    "    \n",
    "    previous_max_difference = 0\n",
    "    while True:\n",
    "        unlabelled_old_centers = unlabelled_centers\n",
    "        unlabelled_centers = move_centers(labelled_clusters)\n",
    "        labelled_clusters = build_clusters(labelled_data, unlabelled_centers)\n",
    "        # we keep old_clusters and clusters so we can get the maximum difference\n",
    "        # between center positions every time. We say the centers have converged\n",
    "        # when the maximum difference between center positions is small.   \n",
    "        differences=[]\n",
    "        for old_center, new_center in zip(unlabelled_old_centers,unlabelled_centers):\n",
    "            ## >>> YOUR CODE HERE: compute the l2 differences between new center and old center\n",
    "            \n",
    "            \n",
    "        max_difference = max(differences)\n",
    "        difference_change = abs((max_difference-previous_max_difference)/np.mean([previous_max_difference,max_difference])) * 100\n",
    "        previous_max_difference = max_difference\n",
    "        # difference change is nan once the list of differences is all zeroes.\n",
    "        if np.isnan(difference_change):\n",
    "            break\n",
    "    return labelled_clusters, unlabelled_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the k-means clustering algorithm upon above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for k-means clustering \n",
    "def cluster(labelled_data, k):\n",
    "    \"\"\"\n",
    "    run k-means clustering on the data. It is assumed that the data is labelled.\n",
    "    \n",
    "    input: labelled_data: datapoints will be clustered.\n",
    "           k: the number of clusters\n",
    "    output: lists of final clusters and centers\n",
    "    \"\"\"\n",
    "    # step 1: initialize centers randomly and set up clusters\n",
    "    ## >>> YOUR CODE HERE: init centers and clusters\n",
    "    \n",
    "    # step 2: update centers util convergence\n",
    "    ## >>> YOUR CODE HERE: repeat until convergence\n",
    "    \n",
    "    \n",
    "    return list(final_clusters), list(final_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help functions after clustering.\n",
    "\n",
    "Run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After clustering\n",
    "def assign_labels_to_centers(clusters, centers):\n",
    "    \"\"\"\n",
    "    Assign a digit label to each cluster.\n",
    "    Cluster is a list of clusters containing labelled datapoints.\n",
    "    NOTE: this function depends on clusters and centers being in the same order.\n",
    "    \"\"\"\n",
    "    labelled_centers = []\n",
    "    for i in range(len(clusters)):\n",
    "        labels = []\n",
    "        for data_tuple in clusters[i]:\n",
    "            labels.append(data_tuple[0])\n",
    "        # pick the most common label\n",
    "        most_common = max(set(labels), key=labels.count)\n",
    "        center = (most_common, centers[i])\n",
    "        labelled_centers.append(center)\n",
    "    return labelled_centers\n",
    "\n",
    "# used for validating and testing\n",
    "def classify_digit(digit, labelled_centers):\n",
    "    \"\"\"\n",
    "    given an unlabelled digit represented by a vector and a list of\n",
    "    labelled centers [(label,vector)], determine the closest center\n",
    "    and thus classify the digit.\n",
    "    \"\"\"\n",
    "    mindistance = float(\"inf\")\n",
    "    for (label, center) in labelled_centers:\n",
    "        distance = np.sqrt(((center - digit)**2).sum())\n",
    "        if distance < mindistance:\n",
    "            mindistance = distance\n",
    "            closest_center_label = label\n",
    "    return closest_center_label\n",
    "\n",
    "# compute error rate after geting final centers\n",
    "def get_error_rate(digits, labelled_centers):\n",
    "    \"\"\"\n",
    "    classifies a list of labelled test digits. returns the error rate.\n",
    "    \"\"\"\n",
    "    classified_incorrect = 0\n",
    "    for (label,vector) in digits:\n",
    "        classified_label = classify_digit(vector, labelled_centers)\n",
    "        if classified_label != label:\n",
    "            classified_incorrect +=1\n",
    "    error_rate = classified_incorrect / float(len(digits))\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run and test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "trained_clusters, trained_centers = cluster(train_data, k)\n",
    "labelled_centers = assign_labels_to_centers(trained_clusters, trained_centers)\n",
    "error_rate = get_error_rate(val_data, labelled_centers)\n",
    "print(f'Error rate of {k} clusters is {error_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the centers we just got with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in labelled_centers:\n",
    "    display_digit(x, \"inferred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the number of clusters\n",
    "\n",
    "What will happen if we set different numbers of clusters? Let us check the error rate regarding the number of clusters, from 5 to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates = {x:None for x in range(5,15)}\n",
    "for k in range(5,15):\n",
    "    trained_clusters, trained_centers = cluster(train_data, k)\n",
    "    labelled_centers = assign_labels_to_centers(trained_clusters, trained_centers)\n",
    "    error_rate = get_error_rate(val_data, labelled_centers)\n",
    "    error_rates[k] = error_rate\n",
    "\n",
    "# Show the error rates\n",
    "x_axis = sorted(error_rates.keys())\n",
    "y_axis = [error_rates[key] for key in x_axis]\n",
    "plt.figure()\n",
    "plt.title(\"Error Rate by Number of Clusters\")\n",
    "plt.scatter(x_axis, y_axis)\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
